---
title: "Wizard of Oz - Express Version"
output:
  pdf_document:
    latex_engine: xelatex
    pandoc_args: "--highlight-style=adam.theme"
---

```{r, echo=FALSE}
knitr::opts_chunk$set(echo=TRUE, message=FALSE, warning=FALSE)
```

# Packages

```{r}
library(dplyr)
library(tidyr)
library(purrr)
library(stringr)
library(tidytext)
library(gutenbergr)
library(lexRankr)
library(knitr)
library(kableExtra)
```

# Wizard of Oz

## Data prep

First download the book. Get rid of chapter titles throughout the book before removing the front matter otherwise they get mixed into
the text. 

The last time I downloaded this book in April 2020, chapter indicators were of the form `4.`, it seems like it has changed now to
`Chapter IV.`! This code might break if they change it again.

```{r, eval=FALSE}
oz_original <- gutenberg_download(55)

chapter_titles <- oz_original %>%
  slice(19:42) %>%
  pull(text) %>%
  # There's a space out front in the TOC
  str_remove_all(pattern=" Chapter [IVX]+\\. ") %>%
  # There's a space in front of Chapter 6's title
  str_remove_all %>%
  paste0("(", ., ")", collapse="|")

oz_original <- oz_original %>%
  mutate(text=str_remove_all(text, pattern=chapter_titles)) %>%
  slice(-c(1:80))
```

We will assume each chapter's sentences are of a similar topic - each chapter will represent a single document. We will perform
LexRank within each chapter. To do this, we will create a list of tibbles where each tibble represents a single chapter. Then we
iterate the LexRank algorithm through each chapter separately.

```{r, eval=FALSE}
oz_prep <- oz_original %>%
  select(-gutenberg_id) %>%
  mutate(chapter=cumsum(str_detect(text, pattern="^Chapter"))) %>%
  mutate(text=str_remove_all(text, pattern="^Chapter.*$")) %>%
  filter(chapter != 0) %>%
  unnest_tokens(output=sentence, input=text, token="sentences", to_lower=FALSE) %>%
  # Cloning a dummy chapter column so I can have one inside and one outside after nesting
  mutate(sentnum=1:n(), chnum=chapter) %>%
  mutate(across(chapter, as.factor)) %>%
  group_by(chnum) %>%
  nest(documents = c(sentence, sentnum, chapter)) %>%
  ungroup() %>%
  pluck("documents")
```

## Do the LexRank

To reduce our reading, we will try to reduce **each** chapter to its top 20% scoring LexRank sentences.
When the LexRank algorithm has finished running, we sort our sentences back in chronological order (rather than sorting by LexRank)
so that we can get a sense of the actual story.

```{r, eval=FALSE}
oz_express <- oz_prep %>%
  map_dfr(
    bind_lexrank, text=sentence, doc_id=chapter, level="sentences",
    usePageRank=TRUE, continuous=TRUE
  ) %>%
  drop_na(lexrank) %>%
  group_by(chapter) %>%
  slice_max(order_by=lexrank, prop=0.2) %>%
  arrange(sentnum)
```

```{r, eval=FALSE, include=FALSE}
saveRDS(oz_express, "./oz.RDS")
```

```{r, echo=FALSE}
oz_express <- readRDS("./oz.RDS")
```

## Oz Express

```{r}
oz_express %>% 
  select(chapter, sentence, lexrank) %>%
  kable(booktabs=TRUE, longtable=TRUE) %>% 
  column_spec(2, width="35em") %>% 
  kable_styling(latex_options = c("hold_position", "repeat_header"))
```

This is still quite a lengthy read. Let's reduce it to just the most important sentences of each chapter.

\newpage

## Oz Speed Run

```{r}
oz_express %>%
  group_by(chapter) %>%
  slice_max(order_by=lexrank, n=1) %>%
  select(chapter, sentence, lexrank) %>%
  kable(booktabs=TRUE, longtable=TRUE) %>%
  column_spec(2, width="35em") %>%
  kable_styling(latex_options = c("hold_position", "repeat_header"))
```

\newpage

```{r, echo=FALSE}
sessioninfo::package_info(
  c("dplyr", "tidyr", "purrr",
    "stringr", "tidytext", "gutenbergr",
    "lexRankr", "knitr", "kableExtra"),
  dependencies = FALSE
)
```